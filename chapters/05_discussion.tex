% !TeX root = ../main.tex
% Add the above to each chapter to make compiling the PDF easier in some editors.

\chapter{Discussion}\label{chapter:discussion}

Peer review is an essential part of the scientific knowledge creation. At the same time, it is a disputatious topic with different camps on how the process should be done, or what its purpose is. Still, there is consensus on many shortcomings of the process and there is clear room for improvement. An area open for experimentation is the peer review recognition and incentivization. Studies and surveys demonstrate there is a clear expectation from the community to recognize review efforts of researchers and the majority thinks the process will improve with more incentives, but the question remains on how to achieve this and what the unintended consequences will be. 

An effort in this direction is the review showcasing platforms, most prominent of them being Publons. As much as they contribute review recognition, here it is argued that such platforms do not align with open science goals and may work against the common benefit of the scientific community. It is also recognized that these problems are rooted in the role these platforms play as trusted third-parties in review verification. To tackle the recognition and incentivization problem, and to avoid the argued problems these platforms may cause, a system was designed that enables verification of peer reviews without a trusted third-party. To best of our knowledge, this work is the first one around this specific problem, and among a few practical works around peer review incentivization.

During the research, the inherent dilemma in the peer review process also became clear. On the one hand, peer review as a scientific process requires transparency and accountability. On the other hand as a scrutinizing process, there is need for anonymity when doing reviews. This dilemma is also at the center of the open vs. blinded reviews debate. Although it does not solve this dilemma, the designed system brings these two ends closer by leveraging emerging standards in the \acrlong{SSI} space such as \acrlong{VC} and \acrlong{DID}s, and cryptographic protocols of \acrlong{zk-proofs}. A working prototype was also developed that demonstrates the technical feasibility of the solution with existing frameworks and libraries. The design and the prototype of the system also contributes as a reference for future \acrlong{VC} works as there exists few system design and development works in this emerging field. 

The interviews reveal several important aspects about the research area and the designed system. First and foremost, with the current degree of recognition and importance given to peer reviews, researchers may not be willing to put much effort on showcasing their peer review records. Therefore, it is crucial to minimize the user input required for such system and automate many processes. Alternatively, the perceived value of showcasing reviews need to be increased. However, this is a much wider problem that requires changing perspectives of institutions, individual researchers, and the scientific community as whole. It was also observed researchers with expressed familiarity with open science practices perceived the system more useful. This feedback was valuable as this is the main value proposition of the system, and that this aspect is the main improvement the designed artifact proposes over the existing systems. Secondly, however, most of the interviewees didn't regard verification of peer reviews as a necessity. This sentiment is connected to the first point above that demonstrating their review records is not worthwhile, and most of the interviewees expressed they don't expect researchers to falsely claim any review experiences. Overall, the depth and the quantity of the interviews were minimal, and these findings suggest further investigation on researchers' attitude towards showcasing reviews would be useful.

Besides, the designed system also has some practical shortcomings. The proposed system require journals to issue peer review credentials. This requirement is a major barrier for adoption as journals must be convinced of the value implementing such a system would bring. Additionally, a very simple peer review process was assumed. As discussed, the process varies a lot among journals. Even though the vocabularies are extensible, there need a degree of agreement to mutual vocabularies. Too much extensibility would break the interoperability in practice. In an ecosystem with many different stakeholders such as peer review, these impose large coordination and governance problems. Stakeholders of peer review are not inclined to change their customs and peer review remains a difficult field to innovate in \parencite[3]{Tennant.2018b}. The platform also exhibits a cold start problem: the platform is as useful as number of users and the peer review data available on the system. It is quite difficult to attract users to an empty platform. As a workaround, it might be beneficial to bootstrap the platform with existing peer reviews (Interviewee 1) such as open peer reviews or reviews available on Publons. Another open issue is who would be willing to maintain such a showcasing platform. The system is proposed here but running and maintaining the system will have costs associated and it is not considered who would take on those costs. To avoid negative attitudes towards the platform, it would be better if it is run by a non-profit or a joint organization instead of a commercial entity. 
 
The system inherits the advantages of \acrshort{SSI} and \acrshort{VC} systems such as verifiability, selective disclosure, and open standards. However, the problems of these systems are also inherited. The system as described here gives agency to its users to manage the credentials in a wallet. If they want to use \acrshort{DID}s, they would also need to manage keys and consider key loss. This is a broader problem in \acrshort{SSI} \acrshort{UX} and more user friendly solutions are needed for the wider adoption of \acrshort{SSI} practices. Nevertheless, the option to avoid user \acrshort{DID}s and the complexities it brings is provided in the system through alternative identifiers such as email or \acrshort{ORCID}. Still, the journal identity is based on the journal domain name and does nor provide any information on the legitimacy of the journal. A verifier also needs to verify if they know the journal and its domain name. 

The domain based identity provides a degree of affiliation to the real world identity. Using \acrshort{DLT}s for identity would require further binding the on-chain identities to real world identities, but would also bring high availability and tamper-proofness to the identities. The decision was made to not use \acrshort{DLT}s for identities to be able to use the journal domain names as identifiers. Another possibility of \acrshort{DLT} use is the hosting of the contexts and schemas. This implementation is kept out of scope of the prototype but this could be included in future work.

Even if the recognition of peer reviews improves, the fundamental questions remain. What constitutes a good peer review and how can it be measured? As Interviewee 5 suggested, a mere number does not express any information on how much the researcher contributes the science. And as with any metric, this could be easily gamed. How can reviewers be incentivized, or should they be incentivized? Here the need for incentivization was pinpointed based on the findings in the literature but no tangible rewards were suggested in this work. How and if the reviewers should be rewarded is still an open question. As with anything that involves humans, peer review is not perfect either. But it could only improve through further research and experimentation.